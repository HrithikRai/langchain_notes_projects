{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from pypdf) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: docx2txt\n",
      "  Building wheel for docx2txt (setup.py): started\n",
      "  Building wheel for docx2txt (setup.py): finished with status 'done'\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3973 sha256=741f529254a6d7445af5e19fd28ca4127988e8635a3a4a4ad1760f7a104ba9b8\n",
      "  Stored in directory: c:\\users\\msi\\appdata\\local\\pip\\cache\\wheels\\22\\58\\cf\\093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
      "Successfully built docx2txt\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import os\n",
    "cohere_api_key = os.getenv('COHERE_API_KEY')\n",
    "from langchain_cohere import ChatCohere\n",
    "chat = ChatCohere(cohere_api_key=cohere_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing: Document loading with PyPDF loader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_pdf = PyPDFLoader('resources/pdf1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_pdf = loader_pdf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'resources/pdf1.pdf', 'page': 0}, page_content='Analysis vs Analytics \\nAlright! So… \\nLet’s discuss the not-so-obvious differences \\nbetween the terms analysis and analytics. \\nDue to the similarity of the words, some people \\nbelieve they share the same meaning, and thus \\nuse them interchangeably. Technically, this \\nisn’t correct. There is, in fact, a distinct \\ndifference between the two. And the reason \\nfor one often being used instead of the other \\nis the lack of a transparent understanding \\nof both. \\nSo, let’s clear this up, shall we? \\nFirst, we will start with analysis. \\nConsider the following… \\nYou have a huge dataset containing data of \\nvarious types. Instead of tackling the entire \\ndataset and running the risk of becoming overwhelmed, \\nyou separate it into easier to digest chunks \\nand study them individually and examine how \\nthey relate to other parts. And that’s analysis \\nin a nutshell. \\nOne important thing to remember, however, \\nis that you perform analyses on things that \\nhave already happened in the past. Such as \\nusing an analysis to explain how a story ended \\nthe way it did or how there was a decrease \\nin sales last summer. \\nAll this means that we do analyses to explain \\nhow and/or why something happened. \\nGreat! \\nNow, this leads us nicely on to the definition \\nof analytics. \\nAs you have probably guessed, analytics generally \\nrefers to the future. Instead of explaining \\npast events it explores potential future ones. \\nAnalytics is essentially the application of \\nlogical and computational reasoning to the \\ncomponent parts obtained in an analysis. And \\nin doing this you are looking for patterns '),\n",
       " Document(metadata={'source': 'resources/pdf1.pdf', 'page': 1}, page_content=\"and exploring what you could do with them \\nin the future. \\nHere, analytics branches off into two areas: \\nqualitative analytics – this is using your \\nintuition and experience in conjunction with \\nthe analysis to plan your next business move. \\nAnd quantitative analytics – this is applying \\nformulas and algorithms to numbers you have \\ngathered from your analysis. \\nHere are a couple of examples. \\nSay, you are an owner of an online clothing \\nstore. You are ahead of the competition and \\nhave a great understanding of what your customer's \\nneeds and wants are. You’ve performed a \\nvery detailed analysis from women’s clothing \\narticles and feel sure about which fashion \\ntrends to follow. You may use this intuition \\nto decide on which styles of clothing to start \\nselling. This would be qualitative analytics. \\nBut you might not know when to introduce the \\nnew collection. In that case, relying on past \\nsales data and user experience data, you could \\npredict in which month it would be best to \\ndo that. This is an example of using quantitative \\nanalytics. \\nFantastic! \\nTo backtrack a little, you can combine these \\nareas with analyses also – you could perform \\nqualitative analysis – to explain how or \\nwhy a story ended the way it did. And you \\ncan perform quantitative analysis – working \\nwith past data to explain how sales decreased \\nlast summer. \\nPerfect! \\nNow that we have cleared up the differences \\nbetween analysis and analytics it shouldn’t \\nbe too difficult to see how terms such as \\n‘data analysis’, ‘data analytics’, \\n‘business analysis’ and ‘business analytics’ \\ncan have their unique meanings too. \\nMore of this will be explained in the next \\nvideo which aims to simplify these, as well \"),\n",
       " Document(metadata={'source': 'resources/pdf1.pdf', 'page': 2}, page_content='as many more with a fantastic diagram. So, \\nlet’s move on! \\nProgramming Languages & Software Employed in Data Science - All the Tools You \\nNeed \\nAlright! So… \\nHow are the techniques used in data, business \\nintelligence, or predictive analytics applied \\nin real life? \\nCertainly, with the help of computers. \\nYou can basically split the relevant tools \\ninto two categories—programming languages \\nand software. \\nKnowing a programming language enables you \\nto devise programs that can execute specific \\noperations. Moreover, you can reuse these \\nprograms whenever you need to execute the \\nsame action. \\nAs you can see from the infographic, R, and \\nPython are the two most popular tools across \\nall columns. Their biggest advantage is that \\nthey can manipulate data and are integrated \\nwithin multiple data and data science software \\nplatforms. They are not just suitable for \\nmathematical and statistical computations. \\nIn other words, R, and Python are adaptable. \\nThey can solve a wide variety of business \\nand data-related problems from beginning to \\nthe end. \\nOf course, R, and Python do have their limitations. \\nThey are not able to address problems specific \\nto some domains. One example is ‘relational \\ndatabase management systems’—there, SQL \\nis king. It was specifically created for that \\npurpose. SQL is at its most advantageous when \\nworking with traditional, historical data. \\nWhen preparing your BI analysis, for instance, \\nyou will surely employ it. \\nOkay. \\nWhen it comes to data science, mentioning '),\n",
       " Document(metadata={'source': 'resources/pdf1.pdf', 'page': 3}, page_content='MATLAB is inevitable. It is ideal for working \\nwith mathematical functions or matrix manipulations. \\nThat’s why it is present in all categories \\nexcept for ‘big data’. While respectable, \\nMATLAB usage is a paid service, and that’s \\none of the reasons why it is losing ground \\nto open-source languages like R and Python. \\nEither way, R, Python, and MATLAB, combined \\nwith SQL, cover most of the tools used when \\nworking with traditional data, BI, and conventional \\ndata science. \\nWhat about big data? \\nApart from R and Python, people working in \\nthis area are often proficient in other languages \\nlike Java or Scala. These two have not been \\ndeveloped specifically for doing statistical \\nanalyses, however they turn out to be very \\nuseful when combining data from multiple sources. \\nAll right! Let’s finish off with machine \\nlearning. \\nWhen it comes to machine learning, we often \\ndeal with big data. Thus, we need a lot of \\ncomputational power, and we can expect people \\nto use the languages similar to those in the \\nbig data column. Apart from R, Python, and \\nMATLAB, other, faster languages are used like \\nJava, JavaScript, C, C++, and Scala. \\nCool. \\nWhat we said may be wonderful, but that’s \\nnot all! \\nBy using one or more programming languages, \\npeople create application software or, as \\nthey are sometimes called, software solutions, \\nthat are adjusted for specific business needs. \\nTheir smaller scope does not make them less \\nuseful, in fact, just the opposite—they \\nare a lot easier to learn and be adopted by \\nothers. You have already heard of several \\nof those. \\nBecause of its ability to do relatively complex \\ncomputations and good visualizations quickly, \\nExcel is a tool applicable to more than one '),\n",
       " Document(metadata={'source': 'resources/pdf1.pdf', 'page': 4}, page_content='category—traditional data, BI, and Data \\nScience. Similarly, SPSS is a very famous \\ntool for working with traditional data and \\napplying statistical analysis. \\nAmong the many applications we have plotted, \\nwe can say there is an increasing amount of \\nsoftware designed for working with big data \\nsuch as Apache Hadoop, Apache Hbase, and Mongo \\nDB. \\nIn terms of big data, Hadoop is the name that \\nmust stick with you. Hadoop is listed as a \\nsoftware in the sense that it is a collection \\nof programs, but don’t imagine it as a nice-looking \\napplication. It’s actually a software framework \\nwhich was designed to address the complexity \\nof big data and its computational intensity. \\nMost notably, Hadoop distributes the computational \\ntasks on multiple computers which is basically \\nthe way to handle big data nowadays. \\nPower BI, SaS, Qlik, and especially Tableau \\nare top-notch examples of software designed \\nfor business intelligence visualizations. \\nIn terms of predictive analytics, EViews is \\nmostly used for working with econometric time-series \\nmodels, and Stata—for academic statistical \\nand econometric research, where techniques \\nlike regression, cluster, and factor analysis \\nare constantly applied. \\nAs a final note, remember the following. \\nShould you have the relevant business and \\ntheoretical knowledge, learning a software \\ntool is relatively easy as opposed to learning \\na programming language. More importantly, \\nit will be sufficient for your need to create \\nquick and accurate analyses. \\nHowever, if your theoretical preparation is \\nstrong enough, you will find yourself restricted \\nby software. Knowing a programming language \\nsuch as R and Python, gives you the freedom \\nto create specific, ad-hoc tools for each \\nproject you are working on. \\nGreat! '),\n",
       " Document(metadata={'source': 'resources/pdf1.pdf', 'page': 5}, page_content='We hope we gave you a good idea about the \\nlevel of applicability of the most frequently \\nused programming and software tools in the \\nfield of data science. \\nThank you for watching! ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pages in the pdf - 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of pages in the pdf - {len(loader_pdf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newline characters consumes token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_pdf_cut = copy.deepcopy(loader_pdf)\n",
    "' '.join(pages_pdf_cut[0].page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pages_pdf_cut:\n",
    "    i.page_content = ' '.join(i.page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'pdf1.pdf', 'page': 0}, page_content='Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns'),\n",
       " Document(metadata={'source': 'pdf1.pdf', 'page': 1}, page_content=\"and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move. And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow. You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics. Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer. Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well\"),\n",
       " Document(metadata={'source': 'pdf1.pdf', 'page': 2}, page_content='as many more with a fantastic diagram. So, let’s move on! Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations. Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end. Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data. When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning'),\n",
       " Document(metadata={'source': 'pdf1.pdf', 'page': 3}, page_content='MATLAB is inevitable. It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science. What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data. Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs. Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one'),\n",
       " Document(metadata={'source': 'pdf1.pdf', 'page': 4}, page_content='category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis. Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application. It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations. In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language. More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on. Great!'),\n",
       " Document(metadata={'source': 'pdf1.pdf', 'page': 5}, page_content='We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_pdf_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docx Loader \n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "loader_docx = Docx2txtLoader(\"resources/pdf1.docx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'resources/pdf1.docx'}, page_content=\"# Introduction to Data and Data Science\\n\\n\\n\\n## Analysis vs Analytics\\n\\n\\n\\nAlright! So…\\nLet’s discuss the not-so-obvious differences\\nbetween the terms analysis and analytics.\\nDue to the similarity of the words, some people\\nbelieve they share the same meaning, and thus\\nuse them interchangeably. Technically, this\\nisn’t correct. There is, in fact, a distinct\\ndifference between the two. And the reason\\nfor one often being used instead of the other\\nis the lack of a transparent understanding\\nof both.\\nSo, let’s clear this up, shall we?\\nFirst, we will start with analysis.\\nConsider the following…\\nYou have a huge dataset containing data of\\nvarious types. Instead of tackling the entire\\ndataset and running the risk of becoming overwhelmed,\\nyou separate it into easier to digest chunks\\nand study them individually and examine how\\nthey relate to other parts. And that’s analysis\\nin a nutshell.\\nOne important thing to remember, however,\\nis that you perform analyses on things that\\nhave already happened in the past. Such as\\nusing an analysis to explain how a story ended\\nthe way it did or how there was a decrease\\nin sales last summer.\\nAll this means that we do analyses to explain\\nhow and/or why something happened.\\nGreat!\\nNow, this leads us nicely on to the definition\\nof analytics.\\nAs you have probably guessed, analytics generally\\nrefers to the future. Instead of explaining\\npast events it explores potential future ones.\\nAnalytics is essentially the application of\\nlogical and computational reasoning to the\\ncomponent parts obtained in an analysis. And\\nin doing this you are looking for patterns\\nand exploring what you could do with them\\nin the future.\\nHere, analytics branches off into two areas:\\nqualitative analytics – this is using your\\nintuition and experience in conjunction with\\nthe analysis to plan your next business move.\\nAnd quantitative analytics – this is applying\\nformulas and algorithms to numbers you have\\ngathered from your analysis.\\nHere are a couple of examples.\\nSay, you are an owner of an online clothing\\nstore. You are ahead of the competition and\\nhave a great understanding of what your customer's\\nneeds and wants are. You’ve performed a\\nvery detailed analysis from women’s clothing\\narticles and feel sure about which fashion\\ntrends to follow. You may use this intuition\\nto decide on which styles of clothing to start\\nselling. This would be qualitative analytics.\\nBut you might not know when to introduce the\\nnew collection. In that case, relying on past\\nsales data and user experience data, you could\\npredict in which month it would be best to\\ndo that. This is an example of using quantitative\\nanalytics.\\nFantastic!\\nTo backtrack a little, you can combine these\\nareas with analyses also – you could perform\\nqualitative analysis – to explain how or\\nwhy a story ended the way it did. And you\\ncan perform quantitative analysis – working\\nwith past data to explain how sales decreased\\nlast summer.\\nPerfect!\\nNow that we have cleared up the differences\\nbetween analysis and analytics it shouldn’t\\nbe too difficult to see how terms such as\\n‘data analysis’, ‘data analytics’,\\n‘business analysis’ and ‘business analytics’\\ncan have their unique meanings too.\\nMore of this will be explained in the next\\nvideo which aims to simplify these, as well\\nas many more with a fantastic diagram. So,\\nlet’s move on!\\n\\n## Programming Languages & Software Employed in Data Science - All the Tools You Need\\n\\n\\n\\nAlright! So…\\nHow are the techniques used in data, business\\nintelligence, or predictive analytics applied\\nin real life?\\nCertainly, with the help of computers.\\nYou can basically split the relevant tools\\ninto two categories—programming languages\\nand software.\\nKnowing a programming language enables you\\nto devise programs that can execute specific\\noperations. Moreover, you can reuse these\\nprograms whenever you need to execute the\\nsame action.\\nAs you can see from the infographic, R, and\\nPython are the two most popular tools across\\nall columns. Their biggest advantage is that\\nthey can manipulate data and are integrated\\nwithin multiple data and data science software\\nplatforms. They are not just suitable for\\nmathematical and statistical computations.\\nIn other words, R, and Python are adaptable.\\nThey can solve a wide variety of business\\nand data-related problems from beginning to\\nthe end.\\nOf course, R, and Python do have their limitations.\\nThey are not able to address problems specific\\nto some domains. One example is ‘relational\\ndatabase management systems’—there, SQL\\nis king. It was specifically created for that\\npurpose. SQL is at its most advantageous when\\nworking with traditional, historical data.\\nWhen preparing your BI analysis, for instance,\\nyou will surely employ it.\\nOkay.\\nWhen it comes to data science, mentioning\\nMATLAB is inevitable. It is ideal for working\\nwith mathematical functions or matrix manipulations.\\nThat’s why it is present in all categories\\nexcept for ‘big data’. While respectable,\\nMATLAB usage is a paid service, and that’s\\none of the reasons why it is losing ground\\nto open-source languages like R and Python.\\nEither way, R, Python, and MATLAB, combined\\nwith SQL, cover most of the tools used when\\nworking with traditional data, BI, and conventional\\ndata science.\\nWhat about big data?\\nApart from R and Python, people working in\\nthis area are often proficient in other languages\\nlike Java or Scala. These two have not been\\ndeveloped specifically for doing statistical\\nanalyses, however they turn out to be very\\nuseful when combining data from multiple sources.\\nAll right! Let’s finish off with machine\\nlearning.\\nWhen it comes to machine learning, we often\\ndeal with big data. Thus, we need a lot of\\ncomputational power, and we can expect people\\nto use the languages similar to those in the\\nbig data column. Apart from R, Python, and\\nMATLAB, other, faster languages are used like\\nJava, JavaScript, C, C++, and Scala.\\nCool.\\nWhat we said may be wonderful, but that’s\\nnot all!\\nBy using one or more programming languages,\\npeople create application software or, as\\nthey are sometimes called, software solutions,\\nthat are adjusted for specific business needs.\\nTheir smaller scope does not make them less\\nuseful, in fact, just the opposite—they\\nare a lot easier to learn and be adopted by\\nothers. You have already heard of several\\nof those.\\nBecause of its ability to do relatively complex\\ncomputations and good visualizations quickly,\\nExcel is a tool applicable to more than one\\ncategory—traditional data, BI, and Data\\nScience. Similarly, SPSS is a very famous\\ntool for working with traditional data and\\napplying statistical analysis.\\nAmong the many applications we have plotted,\\nwe can say there is an increasing amount of\\nsoftware designed for working with big data\\nsuch as Apache Hadoop, Apache Hbase, and Mongo\\nDB.\\nIn terms of big data, Hadoop is the name that\\nmust stick with you. Hadoop is listed as a\\nsoftware in the sense that it is a collection\\nof programs, but don’t imagine it as a nice-looking\\napplication. It’s actually a software framework\\nwhich was designed to address the complexity\\nof big data and its computational intensity.\\nMost notably, Hadoop distributes the computational\\ntasks on multiple computers which is basically\\nthe way to handle big data nowadays.\\nPower BI, SaS, Qlik, and especially Tableau\\nare top-notch examples of software designed\\nfor business intelligence visualizations.\\nIn terms of predictive analytics, EViews is\\nmostly used for working with econometric time-series\\nmodels, and Stata—for academic statistical\\nand econometric research, where techniques\\nlike regression, cluster, and factor analysis\\nare constantly applied.\\nAs a final note, remember the following.\\nShould you have the relevant business and\\ntheoretical knowledge, learning a software\\ntool is relatively easy as opposed to learning\\na programming language. More importantly,\\nit will be sufficient for your need to create\\nquick and accurate analyses.\\nHowever, if your theoretical preparation is\\nstrong enough, you will find yourself restricted\\nby software. Knowing a programming language\\nsuch as R and Python, gives you the freedom\\nto create specific, ad-hoc tools for each\\nproject you are working on.\\nGreat!\\nWe hope we gave you a good idea about the\\nlevel of applicability of the most frequently\\nused programming and software tools in the\\nfield of data science.\\nThank you for watching!\")]\n"
     ]
    }
   ],
   "source": [
    "pages_docx = loader_docx.load()\n",
    "print(pages_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Document splitting - based on characters/chunk\n",
    "for i in range(len(pages_docx)):\n",
    "    pages_docx[i].page_content = ' '.join(pages_docx[i].page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "# to avoid ending them abruptly use . and chunk overlap\n",
    "char_splitter = CharacterTextSplitter(separator=\".\",chunk_size=500,chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_char_split = char_splitter.split_documents(pages_docx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'resources/pdf1.docx'}, page_content='# Introduction to Data and Data Science ## Analysis vs Analytics Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content=\"And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow\"),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well as many more with a fantastic diagram'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='So, let’s move on! ## Programming Languages & Software Employed in Data Science - All the Tools You Need Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end. Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning MATLAB is inevitable. It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science. What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data. Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs. Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on'),\n",
       " Document(metadata={'source': 'resources/pdf1.docx'}, page_content='Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_char_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### single markdown header text splitter, based on splitting topic wise, headers to preserve relevancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter\n",
    "loader_mark = Docx2txtLoader(\"resources/pdf1.docx\")\n",
    "pages = loader_mark.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'resources/pdf1.docx'}, page_content=\"# Introduction to Data and Data Science\\n\\n\\n\\n## Analysis vs Analytics\\n\\n\\n\\nAlright! So…\\nLet’s discuss the not-so-obvious differences\\nbetween the terms analysis and analytics.\\nDue to the similarity of the words, some people\\nbelieve they share the same meaning, and thus\\nuse them interchangeably. Technically, this\\nisn’t correct. There is, in fact, a distinct\\ndifference between the two. And the reason\\nfor one often being used instead of the other\\nis the lack of a transparent understanding\\nof both.\\nSo, let’s clear this up, shall we?\\nFirst, we will start with analysis.\\nConsider the following…\\nYou have a huge dataset containing data of\\nvarious types. Instead of tackling the entire\\ndataset and running the risk of becoming overwhelmed,\\nyou separate it into easier to digest chunks\\nand study them individually and examine how\\nthey relate to other parts. And that’s analysis\\nin a nutshell.\\nOne important thing to remember, however,\\nis that you perform analyses on things that\\nhave already happened in the past. Such as\\nusing an analysis to explain how a story ended\\nthe way it did or how there was a decrease\\nin sales last summer.\\nAll this means that we do analyses to explain\\nhow and/or why something happened.\\nGreat!\\nNow, this leads us nicely on to the definition\\nof analytics.\\nAs you have probably guessed, analytics generally\\nrefers to the future. Instead of explaining\\npast events it explores potential future ones.\\nAnalytics is essentially the application of\\nlogical and computational reasoning to the\\ncomponent parts obtained in an analysis. And\\nin doing this you are looking for patterns\\nand exploring what you could do with them\\nin the future.\\nHere, analytics branches off into two areas:\\nqualitative analytics – this is using your\\nintuition and experience in conjunction with\\nthe analysis to plan your next business move.\\nAnd quantitative analytics – this is applying\\nformulas and algorithms to numbers you have\\ngathered from your analysis.\\nHere are a couple of examples.\\nSay, you are an owner of an online clothing\\nstore. You are ahead of the competition and\\nhave a great understanding of what your customer's\\nneeds and wants are. You’ve performed a\\nvery detailed analysis from women’s clothing\\narticles and feel sure about which fashion\\ntrends to follow. You may use this intuition\\nto decide on which styles of clothing to start\\nselling. This would be qualitative analytics.\\nBut you might not know when to introduce the\\nnew collection. In that case, relying on past\\nsales data and user experience data, you could\\npredict in which month it would be best to\\ndo that. This is an example of using quantitative\\nanalytics.\\nFantastic!\\nTo backtrack a little, you can combine these\\nareas with analyses also – you could perform\\nqualitative analysis – to explain how or\\nwhy a story ended the way it did. And you\\ncan perform quantitative analysis – working\\nwith past data to explain how sales decreased\\nlast summer.\\nPerfect!\\nNow that we have cleared up the differences\\nbetween analysis and analytics it shouldn’t\\nbe too difficult to see how terms such as\\n‘data analysis’, ‘data analytics’,\\n‘business analysis’ and ‘business analytics’\\ncan have their unique meanings too.\\nMore of this will be explained in the next\\nvideo which aims to simplify these, as well\\nas many more with a fantastic diagram. So,\\nlet’s move on!\\n\\n## Programming Languages & Software Employed in Data Science - All the Tools You Need\\n\\n\\n\\nAlright! So…\\nHow are the techniques used in data, business\\nintelligence, or predictive analytics applied\\nin real life?\\nCertainly, with the help of computers.\\nYou can basically split the relevant tools\\ninto two categories—programming languages\\nand software.\\nKnowing a programming language enables you\\nto devise programs that can execute specific\\noperations. Moreover, you can reuse these\\nprograms whenever you need to execute the\\nsame action.\\nAs you can see from the infographic, R, and\\nPython are the two most popular tools across\\nall columns. Their biggest advantage is that\\nthey can manipulate data and are integrated\\nwithin multiple data and data science software\\nplatforms. They are not just suitable for\\nmathematical and statistical computations.\\nIn other words, R, and Python are adaptable.\\nThey can solve a wide variety of business\\nand data-related problems from beginning to\\nthe end.\\nOf course, R, and Python do have their limitations.\\nThey are not able to address problems specific\\nto some domains. One example is ‘relational\\ndatabase management systems’—there, SQL\\nis king. It was specifically created for that\\npurpose. SQL is at its most advantageous when\\nworking with traditional, historical data.\\nWhen preparing your BI analysis, for instance,\\nyou will surely employ it.\\nOkay.\\nWhen it comes to data science, mentioning\\nMATLAB is inevitable. It is ideal for working\\nwith mathematical functions or matrix manipulations.\\nThat’s why it is present in all categories\\nexcept for ‘big data’. While respectable,\\nMATLAB usage is a paid service, and that’s\\none of the reasons why it is losing ground\\nto open-source languages like R and Python.\\nEither way, R, Python, and MATLAB, combined\\nwith SQL, cover most of the tools used when\\nworking with traditional data, BI, and conventional\\ndata science.\\nWhat about big data?\\nApart from R and Python, people working in\\nthis area are often proficient in other languages\\nlike Java or Scala. These two have not been\\ndeveloped specifically for doing statistical\\nanalyses, however they turn out to be very\\nuseful when combining data from multiple sources.\\nAll right! Let’s finish off with machine\\nlearning.\\nWhen it comes to machine learning, we often\\ndeal with big data. Thus, we need a lot of\\ncomputational power, and we can expect people\\nto use the languages similar to those in the\\nbig data column. Apart from R, Python, and\\nMATLAB, other, faster languages are used like\\nJava, JavaScript, C, C++, and Scala.\\nCool.\\nWhat we said may be wonderful, but that’s\\nnot all!\\nBy using one or more programming languages,\\npeople create application software or, as\\nthey are sometimes called, software solutions,\\nthat are adjusted for specific business needs.\\nTheir smaller scope does not make them less\\nuseful, in fact, just the opposite—they\\nare a lot easier to learn and be adopted by\\nothers. You have already heard of several\\nof those.\\nBecause of its ability to do relatively complex\\ncomputations and good visualizations quickly,\\nExcel is a tool applicable to more than one\\ncategory—traditional data, BI, and Data\\nScience. Similarly, SPSS is a very famous\\ntool for working with traditional data and\\napplying statistical analysis.\\nAmong the many applications we have plotted,\\nwe can say there is an increasing amount of\\nsoftware designed for working with big data\\nsuch as Apache Hadoop, Apache Hbase, and Mongo\\nDB.\\nIn terms of big data, Hadoop is the name that\\nmust stick with you. Hadoop is listed as a\\nsoftware in the sense that it is a collection\\nof programs, but don’t imagine it as a nice-looking\\napplication. It’s actually a software framework\\nwhich was designed to address the complexity\\nof big data and its computational intensity.\\nMost notably, Hadoop distributes the computational\\ntasks on multiple computers which is basically\\nthe way to handle big data nowadays.\\nPower BI, SaS, Qlik, and especially Tableau\\nare top-notch examples of software designed\\nfor business intelligence visualizations.\\nIn terms of predictive analytics, EViews is\\nmostly used for working with econometric time-series\\nmodels, and Stata—for academic statistical\\nand econometric research, where techniques\\nlike regression, cluster, and factor analysis\\nare constantly applied.\\nAs a final note, remember the following.\\nShould you have the relevant business and\\ntheoretical knowledge, learning a software\\ntool is relatively easy as opposed to learning\\na programming language. More importantly,\\nit will be sufficient for your need to create\\nquick and accurate analyses.\\nHowever, if your theoretical preparation is\\nstrong enough, you will find yourself restricted\\nby software. Knowing a programming language\\nsuch as R and Python, gives you the freedom\\nto create specific, ad-hoc tools for each\\nproject you are working on.\\nGreat!\\nWe hope we gave you a good idea about the\\nlevel of applicability of the most frequently\\nused programming and software tools in the\\nfield of data science.\\nThank you for watching!\")]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_splitter= MarkdownHeaderTextSplitter(headers_to_split_on=[('#','Course Title'),\n",
    "                                                             ('##','Lecture Title')\n",
    "                                                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_markdown_split = md_splitter.split_text(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content=\"Alright! So…\\nLet’s discuss the not-so-obvious differences\\nbetween the terms analysis and analytics.\\nDue to the similarity of the words, some people\\nbelieve they share the same meaning, and thus\\nuse them interchangeably. Technically, this\\nisn’t correct. There is, in fact, a distinct\\ndifference between the two. And the reason\\nfor one often being used instead of the other\\nis the lack of a transparent understanding\\nof both.\\nSo, let’s clear this up, shall we?\\nFirst, we will start with analysis.\\nConsider the following…\\nYou have a huge dataset containing data of\\nvarious types. Instead of tackling the entire\\ndataset and running the risk of becoming overwhelmed,\\nyou separate it into easier to digest chunks\\nand study them individually and examine how\\nthey relate to other parts. And that’s analysis\\nin a nutshell.\\nOne important thing to remember, however,\\nis that you perform analyses on things that\\nhave already happened in the past. Such as\\nusing an analysis to explain how a story ended\\nthe way it did or how there was a decrease\\nin sales last summer.\\nAll this means that we do analyses to explain\\nhow and/or why something happened.\\nGreat!\\nNow, this leads us nicely on to the definition\\nof analytics.\\nAs you have probably guessed, analytics generally\\nrefers to the future. Instead of explaining\\npast events it explores potential future ones.\\nAnalytics is essentially the application of\\nlogical and computational reasoning to the\\ncomponent parts obtained in an analysis. And\\nin doing this you are looking for patterns\\nand exploring what you could do with them\\nin the future.\\nHere, analytics branches off into two areas:\\nqualitative analytics – this is using your\\nintuition and experience in conjunction with\\nthe analysis to plan your next business move.\\nAnd quantitative analytics – this is applying\\nformulas and algorithms to numbers you have\\ngathered from your analysis.\\nHere are a couple of examples.\\nSay, you are an owner of an online clothing\\nstore. You are ahead of the competition and\\nhave a great understanding of what your customer's\\nneeds and wants are. You’ve performed a\\nvery detailed analysis from women’s clothing\\narticles and feel sure about which fashion\\ntrends to follow. You may use this intuition\\nto decide on which styles of clothing to start\\nselling. This would be qualitative analytics.\\nBut you might not know when to introduce the\\nnew collection. In that case, relying on past\\nsales data and user experience data, you could\\npredict in which month it would be best to\\ndo that. This is an example of using quantitative\\nanalytics.\\nFantastic!\\nTo backtrack a little, you can combine these\\nareas with analyses also – you could perform\\nqualitative analysis – to explain how or\\nwhy a story ended the way it did. And you\\ncan perform quantitative analysis – working\\nwith past data to explain how sales decreased\\nlast summer.\\nPerfect!\\nNow that we have cleared up the differences\\nbetween analysis and analytics it shouldn’t\\nbe too difficult to see how terms such as\\n‘data analysis’, ‘data analytics’,\\n‘business analysis’ and ‘business analytics’\\ncan have their unique meanings too.\\nMore of this will be explained in the next\\nvideo which aims to simplify these, as well\\nas many more with a fantastic diagram. So,\\nlet’s move on!\"),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Alright! So…\\nHow are the techniques used in data, business\\nintelligence, or predictive analytics applied\\nin real life?\\nCertainly, with the help of computers.\\nYou can basically split the relevant tools\\ninto two categories—programming languages\\nand software.\\nKnowing a programming language enables you\\nto devise programs that can execute specific\\noperations. Moreover, you can reuse these\\nprograms whenever you need to execute the\\nsame action.\\nAs you can see from the infographic, R, and\\nPython are the two most popular tools across\\nall columns. Their biggest advantage is that\\nthey can manipulate data and are integrated\\nwithin multiple data and data science software\\nplatforms. They are not just suitable for\\nmathematical and statistical computations.\\nIn other words, R, and Python are adaptable.\\nThey can solve a wide variety of business\\nand data-related problems from beginning to\\nthe end.\\nOf course, R, and Python do have their limitations.\\nThey are not able to address problems specific\\nto some domains. One example is ‘relational\\ndatabase management systems’—there, SQL\\nis king. It was specifically created for that\\npurpose. SQL is at its most advantageous when\\nworking with traditional, historical data.\\nWhen preparing your BI analysis, for instance,\\nyou will surely employ it.\\nOkay.\\nWhen it comes to data science, mentioning\\nMATLAB is inevitable. It is ideal for working\\nwith mathematical functions or matrix manipulations.\\nThat’s why it is present in all categories\\nexcept for ‘big data’. While respectable,\\nMATLAB usage is a paid service, and that’s\\none of the reasons why it is losing ground\\nto open-source languages like R and Python.\\nEither way, R, Python, and MATLAB, combined\\nwith SQL, cover most of the tools used when\\nworking with traditional data, BI, and conventional\\ndata science.\\nWhat about big data?\\nApart from R and Python, people working in\\nthis area are often proficient in other languages\\nlike Java or Scala. These two have not been\\ndeveloped specifically for doing statistical\\nanalyses, however they turn out to be very\\nuseful when combining data from multiple sources.\\nAll right! Let’s finish off with machine\\nlearning.\\nWhen it comes to machine learning, we often\\ndeal with big data. Thus, we need a lot of\\ncomputational power, and we can expect people\\nto use the languages similar to those in the\\nbig data column. Apart from R, Python, and\\nMATLAB, other, faster languages are used like\\nJava, JavaScript, C, C++, and Scala.\\nCool.\\nWhat we said may be wonderful, but that’s\\nnot all!\\nBy using one or more programming languages,\\npeople create application software or, as\\nthey are sometimes called, software solutions,\\nthat are adjusted for specific business needs.\\nTheir smaller scope does not make them less\\nuseful, in fact, just the opposite—they\\nare a lot easier to learn and be adopted by\\nothers. You have already heard of several\\nof those.\\nBecause of its ability to do relatively complex\\ncomputations and good visualizations quickly,\\nExcel is a tool applicable to more than one\\ncategory—traditional data, BI, and Data\\nScience. Similarly, SPSS is a very famous\\ntool for working with traditional data and\\napplying statistical analysis.\\nAmong the many applications we have plotted,\\nwe can say there is an increasing amount of\\nsoftware designed for working with big data\\nsuch as Apache Hadoop, Apache Hbase, and Mongo\\nDB.\\nIn terms of big data, Hadoop is the name that\\nmust stick with you. Hadoop is listed as a\\nsoftware in the sense that it is a collection\\nof programs, but don’t imagine it as a nice-looking\\napplication. It’s actually a software framework\\nwhich was designed to address the complexity\\nof big data and its computational intensity.\\nMost notably, Hadoop distributes the computational\\ntasks on multiple computers which is basically\\nthe way to handle big data nowadays.\\nPower BI, SaS, Qlik, and especially Tableau\\nare top-notch examples of software designed\\nfor business intelligence visualizations.\\nIn terms of predictive analytics, EViews is\\nmostly used for working with econometric time-series\\nmodels, and Stata—for academic statistical\\nand econometric research, where techniques\\nlike regression, cluster, and factor analysis\\nare constantly applied.\\nAs a final note, remember the following.\\nShould you have the relevant business and\\ntheoretical knowledge, learning a software\\ntool is relatively easy as opposed to learning\\na programming language. More importantly,\\nit will be sufficient for your need to create\\nquick and accurate analyses.\\nHowever, if your theoretical preparation is\\nstrong enough, you will find yourself restricted\\nby software. Knowing a programming language\\nsuch as R and Python, gives you the freedom\\nto create specific, ad-hoc tools for each\\nproject you are working on.\\nGreat!\\nWe hope we gave you a good idea about the\\nlevel of applicability of the most frequently\\nused programming and software tools in the\\nfield of data science.\\nThank you for watching!')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_markdown_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the new line characters\n",
    "for i in pages_markdown_split:\n",
    "    i.page_content = ' '.join(i.page_content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content=\"Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis. Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past. Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones. Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move. And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow. You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics. Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer. Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well as many more with a fantastic diagram. So, let’s move on!\"),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations. Moreover, you can reuse these programs whenever you need to execute the same action. As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end. Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data. When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning MATLAB is inevitable. It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science. What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data. Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs. Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis. Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application. It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations. In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language. More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on. Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_markdown_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_markdown_char_split = char_splitter.split_documents(pages_markdown_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Consider the following… You have a huge dataset containing data of various types. Instead of tackling the entire dataset and running the risk of becoming overwhelmed, you separate it into easier to digest chunks and study them individually and examine how they relate to other parts. And that’s analysis in a nutshell. One important thing to remember, however, is that you perform analyses on things that have already happened in the past'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Such as using an analysis to explain how a story ended the way it did or how there was a decrease in sales last summer. All this means that we do analyses to explain how and/or why something happened. Great! Now, this leads us nicely on to the definition of analytics. As you have probably guessed, analytics generally refers to the future. Instead of explaining past events it explores potential future ones'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Analytics is essentially the application of logical and computational reasoning to the component parts obtained in an analysis. And in doing this you are looking for patterns and exploring what you could do with them in the future. Here, analytics branches off into two areas: qualitative analytics – this is using your intuition and experience in conjunction with the analysis to plan your next business move'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content=\"And quantitative analytics – this is applying formulas and algorithms to numbers you have gathered from your analysis. Here are a couple of examples. Say, you are an owner of an online clothing store. You are ahead of the competition and have a great understanding of what your customer's needs and wants are. You’ve performed a very detailed analysis from women’s clothing articles and feel sure about which fashion trends to follow\"),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='You may use this intuition to decide on which styles of clothing to start selling. This would be qualitative analytics. But you might not know when to introduce the new collection. In that case, relying on past sales data and user experience data, you could predict in which month it would be best to do that. This is an example of using quantitative analytics'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Fantastic! To backtrack a little, you can combine these areas with analyses also – you could perform qualitative analysis – to explain how or why a story ended the way it did. And you can perform quantitative analysis – working with past data to explain how sales decreased last summer'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Analysis vs Analytics'}, page_content='Perfect! Now that we have cleared up the differences between analysis and analytics it shouldn’t be too difficult to see how terms such as ‘data analysis’, ‘data analytics’, ‘business analysis’ and ‘business analytics’ can have their unique meanings too. More of this will be explained in the next video which aims to simplify these, as well as many more with a fantastic diagram. So, let’s move on!'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Alright! So… How are the techniques used in data, business intelligence, or predictive analytics applied in real life? Certainly, with the help of computers. You can basically split the relevant tools into two categories—programming languages and software. Knowing a programming language enables you to devise programs that can execute specific operations. Moreover, you can reuse these programs whenever you need to execute the same action'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='As you can see from the infographic, R, and Python are the two most popular tools across all columns. Their biggest advantage is that they can manipulate data and are integrated within multiple data and data science software platforms. They are not just suitable for mathematical and statistical computations. In other words, R, and Python are adaptable. They can solve a wide variety of business and data-related problems from beginning to the end'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Of course, R, and Python do have their limitations. They are not able to address problems specific to some domains. One example is ‘relational database management systems’—there, SQL is king. It was specifically created for that purpose. SQL is at its most advantageous when working with traditional, historical data. When preparing your BI analysis, for instance, you will surely employ it. Okay. When it comes to data science, mentioning MATLAB is inevitable'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='What about big data? Apart from R and Python, people working in this area are often proficient in other languages like Java or Scala. These two have not been developed specifically for doing statistical analyses, however they turn out to be very useful when combining data from multiple sources. All right! Let’s finish off with machine learning. When it comes to machine learning, we often deal with big data'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Thus, we need a lot of computational power, and we can expect people to use the languages similar to those in the big data column. Apart from R, Python, and MATLAB, other, faster languages are used like Java, JavaScript, C, C++, and Scala. Cool. What we said may be wonderful, but that’s not all! By using one or more programming languages, people create application software or, as they are sometimes called, software solutions, that are adjusted for specific business needs'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Their smaller scope does not make them less useful, in fact, just the opposite—they are a lot easier to learn and be adopted by others. You have already heard of several of those. Because of its ability to do relatively complex computations and good visualizations quickly, Excel is a tool applicable to more than one category—traditional data, BI, and Data Science. Similarly, SPSS is a very famous tool for working with traditional data and applying statistical analysis'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='It’s actually a software framework which was designed to address the complexity of big data and its computational intensity. Most notably, Hadoop distributes the computational tasks on multiple computers which is basically the way to handle big data nowadays. Power BI, SaS, Qlik, and especially Tableau are top-notch examples of software designed for business intelligence visualizations'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='In terms of predictive analytics, EViews is mostly used for working with econometric time-series models, and Stata—for academic statistical and econometric research, where techniques like regression, cluster, and factor analysis are constantly applied. As a final note, remember the following. Should you have the relevant business and theoretical knowledge, learning a software tool is relatively easy as opposed to learning a programming language'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='More importantly, it will be sufficient for your need to create quick and accurate analyses. However, if your theoretical preparation is strong enough, you will find yourself restricted by software. Knowing a programming language such as R and Python, gives you the freedom to create specific, ad-hoc tools for each project you are working on'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_markdown_char_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the data\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model=\"embed-english-v3.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embed and save all chunks in a vector store\n",
    "pages_char_split.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (0.5.18)\n",
      "Requirement already satisfied: build>=1.0.3 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (2.9.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.115.4)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.28.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.28.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.49b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.28.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.20.3)\n",
      "Requirement already satisfied: pypika>=0.48.9 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (4.67.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (1.67.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (4.2.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.13.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (0.27.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Requirement already satisfied: pyproject_hooks in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.41.2)\n",
      "Requirement already satisfied: anyio in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.6)\n",
      "Requirement already satisfied: idna in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: sniffio in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.36.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Requirement already satisfied: durationpy>=0.7 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.28.3)\n",
      "Requirement already satisfied: sympy in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-instrumentation==0.49b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.49b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.26.2)\n",
      "Requirement already satisfied: click>=8.0.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.5.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
      "Requirement already satisfied: websockets>=10.4 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in f:\\users\\msi\\miniconda3\\envs\\lanchain_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents = pages_markdown_char_split,\n",
    "                                    embedding=embeddings,\n",
    "                                    persist_directory='./intro_to_ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_18464\\3832563656.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore_from_direc = Chroma(persist_directory='./intro_to_ds',embedding_function=embeddings)\n"
     ]
    }
   ],
   "source": [
    "vectorstore_from_direc = Chroma(persist_directory='./intro_to_ds',embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['d1ced2d5-9120-4143-aac3-a6115686cc66'],\n",
       " 'embeddings': array([[ 0.02619934, -0.00321007,  0.02584839, ...,  0.0496521 ,\n",
       "         -0.00090218,  0.0133667 ]]),\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': None,\n",
       " 'included': [<IncludeEnum.embeddings: 'embeddings'>]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manage content within vector store\n",
    "vectorstore_from_direc.get(ids='d1ced2d5-9120-4143-aac3-a6115686cc66',include=['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new doc\n",
    "from langchain_core.documents import Document\n",
    "added_doc = Document(page_content='Alright! So… Let’s discuss the not-so-obvious differences between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis',\n",
    "                     metadata={'Course Title': 'Introduction to Data and Data Science',\n",
    "                                'Lecture Title': 'Analysis vs Analytics'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9413ba0f-a37f-4bef-bde4-aeca5422f8b9']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_from_direc.add_documents([added_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['9413ba0f-a37f-4bef-bde4-aeca5422f8b9'],\n",
       " 'embeddings': array([[ 0.03086853, -0.00647736,  0.02738953, ...,  0.0519104 ,\n",
       "         -0.01875305,  0.01399231]]),\n",
       " 'documents': None,\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': None,\n",
       " 'included': [<IncludeEnum.embeddings: 'embeddings'>]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_from_direc.get(ids='9413ba0f-a37f-4bef-bde4-aeca5422f8b9',include=['embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_doc = Document(page_content='I hope you understand it now, once again so between the terms analysis and analytics. Due to the similarity of the words, some people believe they share the same meaning, and thus use them interchangeably. Technically, this isn’t correct. There is, in fact, a distinct difference between the two. And the reason for one often being used instead of the other is the lack of a transparent understanding of both. So, let’s clear this up, shall we? First, we will start with analysis',\n",
    "                     metadata={'Course Title': 'Introduction to Data and Data Science',\n",
    "                                'Lecture Title': 'Analysis vs Analytics'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update document\n",
    "vectorstore_from_direc.update_document(document_id='9413ba0f-a37f-4bef-bde4-aeca5422f8b9',document=updated_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete doc\n",
    "vectorstore_from_direc.delete('9413ba0f-a37f-4bef-bde4-aeca5422f8b9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:\n",
    "### Define a question related to DS\n",
    "### Create a vector rep of the ques\n",
    "### Retrieve a preselected number of documents relevant to this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What softwares do Data Scientists use?\"\n",
    "retrieved_documents = vectorstore.similarity_search(query=question,\n",
    "                                                    k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application'),\n",
       " Document(metadata={'Course Title': 'Introduction to Data and Data Science', 'Lecture Title': 'Programming Languages & Software Employed in Data Science - All the Tools You Need'}, page_content='It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Content: Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!\n",
      "--------\n",
      "Programming Languages & Software Employed in Data Science - All the Tools You Need\n",
      "Page Content: Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application\n",
      "--------\n",
      "Programming Languages & Software Employed in Data Science - All the Tools You Need\n",
      "Page Content: It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science\n",
      "--------\n",
      "Programming Languages & Software Employed in Data Science - All the Tools You Need\n"
     ]
    }
   ],
   "source": [
    "for i in retrieved_documents:\n",
    "    print(f\"Page Content: {i.page_content}\\n--------\\n{i.metadata['Lecture Title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAximal MArginal Relevance Search - avoid redundancy in answers and find more relevant docs\n",
    "# we have two similarities score, one with the retirved docs and the questions denoting relevancy(maximise this)\n",
    "# other among the retrieved docs depicting redundancy(minmize this)\n",
    "# marginal relevance = (a)relavance - (1-a)diversity(s1-s2)\n",
    "# The param contrlling the balance is lambda(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What softwares do Data Scientists use?\"\n",
    "# diversity vs relevance\n",
    "# if lambda_mult = 1, it's aiming only for relevance\n",
    "retrieved_documents = vectorstore.max_marginal_relevance_search(query=question,\n",
    "                                                    k=3,\n",
    "                                                    lambda_mult=1,\n",
    "                                                    filter = {\"Lecture Title\":\"Programming Languages & Software Employed in Data Science - All the Tools You Need\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Content: Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!\n",
      "--------\n",
      "Programming Languages & Software Employed in Data Science - All the Tools You Need\n",
      "Page Content: Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application\n",
      "--------\n",
      "Programming Languages & Software Employed in Data Science - All the Tools You Need\n",
      "Page Content: It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science\n",
      "--------\n",
      "Programming Languages & Software Employed in Data Science - All the Tools You Need\n"
     ]
    }
   ],
   "source": [
    "for i in retrieved_documents:\n",
    "    print(f\"Page Content: {i.page_content}\\n--------\\n{i.metadata['Lecture Title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a runnable retrieval object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type='mmr',search_kwargs={'k':3,'lambda_mult':0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'CohereEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001DE428D7A30>, search_type='mmr', search_kwargs={'k': 3, 'lambda_mult': 0.7})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever\n",
    "# VectorStoreRetriever class inherits from the runnable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! We hope we gave you a good idea about the level of applicability of the most frequently used programming and software tools in the field of data science. Thank you for watching!/n ---------------------\n",
      "Among the many applications we have plotted, we can say there is an increasing amount of software designed for working with big data such as Apache Hadoop, Apache Hbase, and Mongo DB. In terms of big data, Hadoop is the name that must stick with you. Hadoop is listed as a software in the sense that it is a collection of programs, but don’t imagine it as a nice-looking application/n ---------------------\n",
      "It is ideal for working with mathematical functions or matrix manipulations. That’s why it is present in all categories except for ‘big data’. While respectable, MATLAB usage is a paid service, and that’s one of the reasons why it is losing ground to open-source languages like R and Python. Either way, R, Python, and MATLAB, combined with SQL, cover most of the tools used when working with traditional data, BI, and conventional data science/n ---------------------\n"
     ]
    }
   ],
   "source": [
    "for i in retrieved_documents:\n",
    "    print(i.page_content + \"/n ---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATION\n",
    "TEMPLATE = '''\n",
    "Answer the following question:\n",
    "{question}\n",
    "\n",
    "To answer the question use only the following context\n",
    "{context}\n",
    "\n",
    "At the end of the response, specify the name of the lecture from where this content is taken from\n",
    "in the format\n",
    "Resources: *Lecture Title*\n",
    "where *Lecture Title* should be substituted with the title of all resource lectures.\n",
    "'''\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(template = TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCohere(client=<cohere.client.Client object at 0x000001DE24466290>, async_client=<cohere.client.AsyncClient object at 0x000001DE244662C0>, cohere_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What softwares do data scientists use?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough,RunnableParallel\n",
    "chain = RunnableParallel({'context':retriever,\n",
    "         'question':RunnablePassthrough()}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ({'context':retriever,\n",
    "         'question':RunnablePassthrough()} | prompt_template | chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Data Scientists have a wide range of software tools at their disposal, depending on the type of data they are working with. For instance, when dealing with big data, Apache Hadoop, Apache Hbase, and Mongo DB are commonly used. Hadoop, in particular, is a collection of programs that facilitate working with large datasets.\\n\\nIn the context of traditional data, Business Intelligence (BI), and conventional data science, R, Python, MATLAB, and SQL are the most prevalent tools. MATLAB is a paid service, ideal for mathematical functions and matrix manipulations, but it is losing popularity to open-source languages like R and Python.\\n\\nResources: *Programming Languages & Software Employed in Data Science - All the Tools You Need*' additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '481c82ae-00eb-4363-a71a-9945cda66d9d', 'token_count': {'input_tokens': 623.0, 'output_tokens': 147.0}} response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '481c82ae-00eb-4363-a71a-9945cda66d9d', 'token_count': {'input_tokens': 623.0, 'output_tokens': 147.0}} id='run-47543aab-64e9-4438-8659-622d991ac187-0' usage_metadata={'input_tokens': 623, 'output_tokens': 147, 'total_tokens': 770}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "str_out = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ({'context':retriever,\n",
    "         'question':RunnablePassthrough()} | prompt_template | chat | str_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scientists have a wide range of software tools at their disposal, depending on the type of data they are working with. For traditional data, BI, and conventional data science, the most commonly used tools are R, Python, MATLAB, and SQL. These languages are versatile and cover most of the tasks required in these areas. However, MATLAB is a paid service, which has led to a decline in its usage compared to open-source alternatives like R and Python.\n",
      "\n",
      "When it comes to big data, Apache Hadoop is a prominent software collection that is widely used. Other software designed for big data includes Apache Hbase and Mongo DB.\n",
      "\n",
      "Resources: *Programming Languages & Software Employed in Data Science - All the Tools You Need*\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuffing - Inserting all retrieved documents into the prompt but might fail\n",
    "# if the content > context_window\n",
    "# also as research shows lms uses information primarily from end or beginning of document list,\n",
    "# therefore information in the middle might go disregarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There we need document refinement, passing documents to the model one at a time\n",
    "# Therefore incrementally updating the new response with the old information it has received.\n",
    "# but more calls to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lanchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
